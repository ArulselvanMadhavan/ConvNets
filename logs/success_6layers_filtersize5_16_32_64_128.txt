Loading ../data/train.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "train.h5" (mode r)>)
Loading ../data/test.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "test.h5" (mode r)>)
(50000, 3072)	(50000,)	(10000, 3072)	(10000,)

loss: 48.784540 after (Iteration 1 / 19600)
loss: 20.596258 after (Iteration 101 / 19600)
loss: 20.147456 after (Iteration 201 / 19600)
loss: 19.931520 after (Iteration 301 / 19600)
loss: 19.872068 after (Iteration 401 / 19600)
loss: 19.720194 after (Iteration 501 / 19600)
loss: 19.745298 after (Iteration 601 / 19600)
loss: 19.979180 after (Iteration 701 / 19600)
loss: 19.707411 after (Iteration 801 / 19600)
loss: 20.008544 after (Iteration 901 / 19600)
(Epoch 1 / 20) train_acc: 0.579000; val_acc: 0.573000
loss: 20.212967 after (Iteration 1001 / 19600)
loss: 20.349521 after (Iteration 1101 / 19600)
loss: 20.605029 after (Iteration 1201 / 19600)
loss: 20.898903 after (Iteration 1301 / 19600)
loss: 20.915315 after (Iteration 1401 / 19600)
loss: 21.511463 after (Iteration 1501 / 19600)
loss: 21.598357 after (Iteration 1601 / 19600)
loss: 21.731361 after (Iteration 1701 / 19600)
loss: 22.014077 after (Iteration 1801 / 19600)
loss: 22.475613 after (Iteration 1901 / 19600)
(Epoch 2 / 20) train_acc: 0.566000; val_acc: 0.583000
loss: 22.772400 after (Iteration 2001 / 19600)
loss: 22.789156 after (Iteration 2101 / 19600)
loss: 23.233898 after (Iteration 2201 / 19600)
loss: 23.728683 after (Iteration 2301 / 19600)
loss: 23.681845 after (Iteration 2401 / 19600)
loss: 24.416364 after (Iteration 2501 / 19600)
loss: 24.639197 after (Iteration 2601 / 19600)
loss: 24.645520 after (Iteration 2701 / 19600)
loss: 25.324494 after (Iteration 2801 / 19600)
loss: 25.429012 after (Iteration 2901 / 19600)
(Epoch 3 / 20) train_acc: 0.689000; val_acc: 0.645000
loss: 26.366208 after (Iteration 3001 / 19600)
loss: 26.365927 after (Iteration 3101 / 19600)
loss: 26.547780 after (Iteration 3201 / 19600)
loss: 26.985629 after (Iteration 3301 / 19600)
loss: 27.406837 after (Iteration 3401 / 19600)
loss: 27.849089 after (Iteration 3501 / 19600)
loss: 28.119876 after (Iteration 3601 / 19600)
loss: 28.337754 after (Iteration 3701 / 19600)
loss: 29.140146 after (Iteration 3801 / 19600)
loss: 29.226006 after (Iteration 3901 / 19600)
(Epoch 4 / 20) train_acc: 0.753000; val_acc: 0.670000
loss: 29.524695 after (Iteration 4001 / 19600)
loss: 29.913821 after (Iteration 4101 / 19600)
loss: 30.143762 after (Iteration 4201 / 19600)
loss: 30.818471 after (Iteration 4301 / 19600)
loss: 30.978962 after (Iteration 4401 / 19600)
loss: 31.586779 after (Iteration 4501 / 19600)
loss: 31.593120 after (Iteration 4601 / 19600)
loss: 32.155936 after (Iteration 4701 / 19600)
loss: 32.490968 after (Iteration 4801 / 19600)
(Epoch 5 / 20) train_acc: 0.794000; val_acc: 0.686000
loss: 32.804888 after (Iteration 4901 / 19600)
loss: 33.588794 after (Iteration 5001 / 19600)
loss: 33.950433 after (Iteration 5101 / 19600)
loss: 33.962647 after (Iteration 5201 / 19600)
loss: 34.190325 after (Iteration 5301 / 19600)
loss: 34.878675 after (Iteration 5401 / 19600)
loss: 35.192680 after (Iteration 5501 / 19600)
loss: 36.016238 after (Iteration 5601 / 19600)
loss: 36.016856 after (Iteration 5701 / 19600)
loss: 36.224919 after (Iteration 5801 / 19600)
(Epoch 6 / 20) train_acc: 0.831000; val_acc: 0.686000
loss: 36.964903 after (Iteration 5901 / 19600)
loss: 37.211133 after (Iteration 6001 / 19600)
loss: 37.541801 after (Iteration 6101 / 19600)
loss: 37.954135 after (Iteration 6201 / 19600)
loss: 38.160664 after (Iteration 6301 / 19600)
loss: 38.636040 after (Iteration 6401 / 19600)
loss: 39.309533 after (Iteration 6501 / 19600)
loss: 39.410087 after (Iteration 6601 / 19600)
loss: 39.597562 after (Iteration 6701 / 19600)
loss: 40.211724 after (Iteration 6801 / 19600)
(Epoch 7 / 20) train_acc: 0.837000; val_acc: 0.701000
loss: 40.560140 after (Iteration 6901 / 19600)
loss: 40.864224 after (Iteration 7001 / 19600)
loss: 41.200577 after (Iteration 7101 / 19600)
loss: 41.485074 after (Iteration 7201 / 19600)
loss: 41.821308 after (Iteration 7301 / 19600)
loss: 42.369870 after (Iteration 7401 / 19600)
loss: 42.505636 after (Iteration 7501 / 19600)
loss: 42.992108 after (Iteration 7601 / 19600)
loss: 43.177584 after (Iteration 7701 / 19600)
loss: 43.632406 after (Iteration 7801 / 19600)
(Epoch 8 / 20) train_acc: 0.876000; val_acc: 0.704000
loss: 44.103475 after (Iteration 7901 / 19600)
loss: 44.539674 after (Iteration 8001 / 19600)
loss: 44.807485 after (Iteration 8101 / 19600)
loss: 45.062059 after (Iteration 8201 / 19600)
loss: 45.360262 after (Iteration 8301 / 19600)
loss: 45.713712 after (Iteration 8401 / 19600)
loss: 45.912474 after (Iteration 8501 / 19600)
loss: 46.162162 after (Iteration 8601 / 19600)
loss: 46.851247 after (Iteration 8701 / 19600)
loss: 47.176766 after (Iteration 8801 / 19600)
(Epoch 9 / 20) train_acc: 0.898000; val_acc: 0.701000
loss: 47.477464 after (Iteration 8901 / 19600)
loss: 47.704245 after (Iteration 9001 / 19600)
loss: 47.894719 after (Iteration 9101 / 19600)
loss: 48.275625 after (Iteration 9201 / 19600)
loss: 48.561393 after (Iteration 9301 / 19600)
loss: 48.752125 after (Iteration 9401 / 19600)
loss: 49.055239 after (Iteration 9501 / 19600)
loss: 49.436133 after (Iteration 9601 / 19600)
loss: 49.754744 after (Iteration 9701 / 19600)
(Epoch 10 / 20) train_acc: 0.923000; val_acc: 0.708000
loss: 49.905821 after (Iteration 9801 / 19600)
loss: 50.284790 after (Iteration 9901 / 19600)
loss: 50.470577 after (Iteration 10001 / 19600)
loss: 51.003304 after (Iteration 10101 / 19600)
loss: 51.191056 after (Iteration 10201 / 19600)
loss: 51.336418 after (Iteration 10301 / 19600)
loss: 51.565436 after (Iteration 10401 / 19600)
loss: 51.793499 after (Iteration 10501 / 19600)
loss: 52.607040 after (Iteration 10601 / 19600)
loss: 52.355936 after (Iteration 10701 / 19600)
(Epoch 11 / 20) train_acc: 0.918000; val_acc: 0.715000
loss: 52.774186 after (Iteration 10801 / 19600)
loss: 53.004405 after (Iteration 10901 / 19600)
loss: 53.254339 after (Iteration 11001 / 19600)
loss: 53.671846 after (Iteration 11101 / 19600)
loss: 53.808301 after (Iteration 11201 / 19600)
loss: 53.903566 after (Iteration 11301 / 19600)
loss: 53.983237 after (Iteration 11401 / 19600)
loss: 54.439001 after (Iteration 11501 / 19600)
loss: 54.560573 after (Iteration 11601 / 19600)
loss: 54.737388 after (Iteration 11701 / 19600)
(Epoch 12 / 20) train_acc: 0.927000; val_acc: 0.711000
loss: 55.141270 after (Iteration 11801 / 19600)
loss: 55.502494 after (Iteration 11901 / 19600)
loss: 55.559036 after (Iteration 12001 / 19600)
loss: 55.827851 after (Iteration 12101 / 19600)
loss: 55.843760 after (Iteration 12201 / 19600)
loss: 56.067895 after (Iteration 12301 / 19600)
loss: 56.281840 after (Iteration 12401 / 19600)
loss: 56.509609 after (Iteration 12501 / 19600)
loss: 56.862443 after (Iteration 12601 / 19600)
loss: 57.118944 after (Iteration 12701 / 19600)
(Epoch 13 / 20) train_acc: 0.951000; val_acc: 0.719000
loss: 57.308755 after (Iteration 12801 / 19600)
loss: 57.413908 after (Iteration 12901 / 19600)
loss: 57.539882 after (Iteration 13001 / 19600)
loss: 57.729160 after (Iteration 13101 / 19600)
loss: 57.943773 after (Iteration 13201 / 19600)
loss: 58.113307 after (Iteration 13301 / 19600)
loss: 58.293850 after (Iteration 13401 / 19600)
loss: 58.570872 after (Iteration 13501 / 19600)
loss: 58.715221 after (Iteration 13601 / 19600)
loss: 58.866255 after (Iteration 13701 / 19600)
(Epoch 14 / 20) train_acc: 0.960000; val_acc: 0.714000
loss: 58.998125 after (Iteration 13801 / 19600)
loss: 59.412241 after (Iteration 13901 / 19600)
loss: 59.422730 after (Iteration 14001 / 19600)
loss: 59.651444 after (Iteration 14101 / 19600)
loss: 59.969052 after (Iteration 14201 / 19600)
loss: 59.954229 after (Iteration 14301 / 19600)
loss: 60.223656 after (Iteration 14401 / 19600)
loss: 60.435457 after (Iteration 14501 / 19600)
loss: 60.704280 after (Iteration 14601 / 19600)
(Epoch 15 / 20) train_acc: 0.957000; val_acc: 0.694000
loss: 60.645269 after (Iteration 14701 / 19600)
loss: 60.958818 after (Iteration 14801 / 19600)
loss: 60.960203 after (Iteration 14901 / 19600)
loss: 61.110678 after (Iteration 15001 / 19600)
loss: 61.363798 after (Iteration 15101 / 19600)
loss: 61.538076 after (Iteration 15201 / 19600)
loss: 61.764685 after (Iteration 15301 / 19600)
loss: 61.715586 after (Iteration 15401 / 19600)
loss: 61.905617 after (Iteration 15501 / 19600)
loss: 62.013024 after (Iteration 15601 / 19600)
(Epoch 16 / 20) train_acc: 0.966000; val_acc: 0.701000
loss: 62.318725 after (Iteration 15701 / 19600)
loss: 62.382887 after (Iteration 15801 / 19600)
loss: 62.686553 after (Iteration 15901 / 19600)
loss: 62.621353 after (Iteration 16001 / 19600)
loss: 62.752492 after (Iteration 16101 / 19600)
loss: 62.846154 after (Iteration 16201 / 19600)
loss: 63.053387 after (Iteration 16301 / 19600)
loss: 63.161207 after (Iteration 16401 / 19600)
loss: 63.659866 after (Iteration 16501 / 19600)
loss: 63.461718 after (Iteration 16601 / 19600)
(Epoch 17 / 20) train_acc: 0.981000; val_acc: 0.710000
loss: 63.772719 after (Iteration 16701 / 19600)
loss: 63.733131 after (Iteration 16801 / 19600)
loss: 63.838494 after (Iteration 16901 / 19600)
loss: 64.112230 after (Iteration 17001 / 19600)
loss: 64.142011 after (Iteration 17101 / 19600)
loss: 64.230722 after (Iteration 17201 / 19600)
loss: 64.362255 after (Iteration 17301 / 19600)
loss: 64.508800 after (Iteration 17401 / 19600)
loss: 64.613120 after (Iteration 17501 / 19600)
loss: 64.746560 after (Iteration 17601 / 19600)
(Epoch 18 / 20) train_acc: 0.975000; val_acc: 0.712000
loss: 64.884396 after (Iteration 17701 / 19600)
loss: 65.006750 after (Iteration 17801 / 19600)
loss: 65.025914 after (Iteration 17901 / 19600)
loss: 65.396823 after (Iteration 18001 / 19600)
loss: 65.502157 after (Iteration 18101 / 19600)
loss: 65.507579 after (Iteration 18201 / 19600)
loss: 65.625481 after (Iteration 18301 / 19600)
loss: 65.710150 after (Iteration 18401 / 19600)
loss: 65.987961 after (Iteration 18501 / 19600)
loss: 65.930102 after (Iteration 18601 / 19600)
(Epoch 19 / 20) train_acc: 0.969000; val_acc: 0.707000
loss: 66.037123 after (Iteration 18701 / 19600)
loss: 66.086654 after (Iteration 18801 / 19600)
loss: 66.272898 after (Iteration 18901 / 19600)
loss: 66.393216 after (Iteration 19001 / 19600)
loss: 66.557047 after (Iteration 19101 / 19600)
loss: 66.537306 after (Iteration 19201 / 19600)
loss: 66.594388 after (Iteration 19301 / 19600)
loss: 66.699285 after (Iteration 19401 / 19600)
loss: 66.855189 after (Iteration 19501 / 19600)
(Epoch 20 / 20) train_acc: 0.982000; val_acc: 0.715000
Test Accuracy:0.7164