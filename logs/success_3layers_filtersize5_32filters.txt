Loading ../data/train.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "train.h5" (mode r)>)
Loading ../data/test.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "test.h5" (mode r)>)
(50000, 3072)	(50000,)	(10000, 3072)	(10000,)

loss: 115.985170 after (Iteration 1 / 19600)
loss: 41.864949 after (Iteration 101 / 19600)
loss: 30.207279 after (Iteration 201 / 19600)
loss: 21.701880 after (Iteration 301 / 19600)
loss: 15.714216 after (Iteration 401 / 19600)
loss: 11.405061 after (Iteration 501 / 19600)
loss: 8.599003 after (Iteration 601 / 19600)
loss: 6.349247 after (Iteration 701 / 19600)
loss: 5.157434 after (Iteration 801 / 19600)
loss: 4.330005 after (Iteration 901 / 19600)
(Epoch 1 / 20) train_acc: 0.237000; val_acc: 0.282000
loss: 3.417057 after (Iteration 1001 / 19600)
loss: 3.350918 after (Iteration 1101 / 19600)
loss: 2.949699 after (Iteration 1201 / 19600)
loss: 2.964640 after (Iteration 1301 / 19600)
loss: 2.298138 after (Iteration 1401 / 19600)
loss: 2.318209 after (Iteration 1501 / 19600)
loss: 2.149694 after (Iteration 1601 / 19600)
loss: 2.030042 after (Iteration 1701 / 19600)
loss: 2.270176 after (Iteration 1801 / 19600)
loss: 1.811389 after (Iteration 1901 / 19600)
(Epoch 2 / 20) train_acc: 0.295000; val_acc: 0.306000
loss: 2.199060 after (Iteration 2001 / 19600)
loss: 2.107111 after (Iteration 2101 / 19600)
loss: 2.193739 after (Iteration 2201 / 19600)
loss: 1.845411 after (Iteration 2301 / 19600)
loss: 1.779949 after (Iteration 2401 / 19600)
loss: 1.803541 after (Iteration 2501 / 19600)
loss: 1.904050 after (Iteration 2601 / 19600)
loss: 1.950721 after (Iteration 2701 / 19600)
loss: 1.825361 after (Iteration 2801 / 19600)
loss: 1.979473 after (Iteration 2901 / 19600)
(Epoch 3 / 20) train_acc: 0.378000; val_acc: 0.381000
loss: 2.001015 after (Iteration 3001 / 19600)
loss: 1.778007 after (Iteration 3101 / 19600)
loss: 1.988280 after (Iteration 3201 / 19600)
loss: 1.832265 after (Iteration 3301 / 19600)
loss: 2.001592 after (Iteration 3401 / 19600)
loss: 1.760566 after (Iteration 3501 / 19600)
loss: 1.727554 after (Iteration 3601 / 19600)
loss: 1.745283 after (Iteration 3701 / 19600)
loss: 1.936654 after (Iteration 3801 / 19600)
loss: 1.919167 after (Iteration 3901 / 19600)
(Epoch 4 / 20) train_acc: 0.419000; val_acc: 0.388000
loss: 1.976557 after (Iteration 4001 / 19600)
loss: 1.928460 after (Iteration 4101 / 19600)
loss: 1.769168 after (Iteration 4201 / 19600)
loss: 1.783246 after (Iteration 4301 / 19600)
loss: 2.060263 after (Iteration 4401 / 19600)
loss: 1.910489 after (Iteration 4501 / 19600)
loss: 1.585994 after (Iteration 4601 / 19600)
loss: 1.813305 after (Iteration 4701 / 19600)
loss: 1.866242 after (Iteration 4801 / 19600)
(Epoch 5 / 20) train_acc: 0.433000; val_acc: 0.427000
loss: 1.710674 after (Iteration 4901 / 19600)
loss: 1.810493 after (Iteration 5001 / 19600)
loss: 1.637061 after (Iteration 5101 / 19600)
loss: 1.624138 after (Iteration 5201 / 19600)
loss: 1.747389 after (Iteration 5301 / 19600)
loss: 1.802369 after (Iteration 5401 / 19600)
loss: 1.934642 after (Iteration 5501 / 19600)
loss: 1.665730 after (Iteration 5601 / 19600)
loss: 1.895406 after (Iteration 5701 / 19600)
loss: 1.609360 after (Iteration 5801 / 19600)
(Epoch 6 / 20) train_acc: 0.408000; val_acc: 0.416000
loss: 1.699013 after (Iteration 5901 / 19600)
loss: 1.725728 after (Iteration 6001 / 19600)
loss: 1.604821 after (Iteration 6101 / 19600)
loss: 2.021782 after (Iteration 6201 / 19600)
loss: 1.868318 after (Iteration 6301 / 19600)
loss: 1.636527 after (Iteration 6401 / 19600)
loss: 1.722497 after (Iteration 6501 / 19600)
loss: 1.876391 after (Iteration 6601 / 19600)
loss: 1.508573 after (Iteration 6701 / 19600)
loss: 1.920968 after (Iteration 6801 / 19600)
(Epoch 7 / 20) train_acc: 0.388000; val_acc: 0.407000
loss: 1.800633 after (Iteration 6901 / 19600)
loss: 1.933446 after (Iteration 7001 / 19600)
loss: 1.618569 after (Iteration 7101 / 19600)
loss: 1.676965 after (Iteration 7201 / 19600)
loss: 1.808916 after (Iteration 7301 / 19600)
loss: 1.625009 after (Iteration 7401 / 19600)
loss: 1.693070 after (Iteration 7501 / 19600)
loss: 1.714701 after (Iteration 7601 / 19600)
loss: 1.700982 after (Iteration 7701 / 19600)
loss: 1.556900 after (Iteration 7801 / 19600)
(Epoch 8 / 20) train_acc: 0.468000; val_acc: 0.455000
loss: 1.528424 after (Iteration 7901 / 19600)
loss: 1.777448 after (Iteration 8001 / 19600)
loss: 1.840047 after (Iteration 8101 / 19600)
loss: 1.855587 after (Iteration 8201 / 19600)
loss: 1.764858 after (Iteration 8301 / 19600)
loss: 1.730257 after (Iteration 8401 / 19600)
loss: 1.623354 after (Iteration 8501 / 19600)
loss: 1.605390 after (Iteration 8601 / 19600)
loss: 1.744780 after (Iteration 8701 / 19600)
loss: 1.767066 after (Iteration 8801 / 19600)
(Epoch 9 / 20) train_acc: 0.468000; val_acc: 0.449000
loss: 1.495381 after (Iteration 8901 / 19600)
loss: 1.495812 after (Iteration 9001 / 19600)
loss: 1.522751 after (Iteration 9101 / 19600)
loss: 1.371818 after (Iteration 9201 / 19600)
loss: 1.748277 after (Iteration 9301 / 19600)
loss: 1.741295 after (Iteration 9401 / 19600)
loss: 1.595167 after (Iteration 9501 / 19600)
loss: 1.816474 after (Iteration 9601 / 19600)
loss: 1.562931 after (Iteration 9701 / 19600)
(Epoch 10 / 20) train_acc: 0.451000; val_acc: 0.452000
loss: 1.894181 after (Iteration 9801 / 19600)
loss: 1.535359 after (Iteration 9901 / 19600)
loss: 1.984414 after (Iteration 10001 / 19600)
loss: 1.556262 after (Iteration 10101 / 19600)
loss: 1.790434 after (Iteration 10201 / 19600)
loss: 1.636884 after (Iteration 10301 / 19600)
loss: 1.926541 after (Iteration 10401 / 19600)
loss: 1.796220 after (Iteration 10501 / 19600)
loss: 1.534551 after (Iteration 10601 / 19600)
loss: 1.595899 after (Iteration 10701 / 19600)
(Epoch 11 / 20) train_acc: 0.436000; val_acc: 0.455000
loss: 1.718517 after (Iteration 10801 / 19600)
loss: 1.853703 after (Iteration 10901 / 19600)
loss: 1.912549 after (Iteration 11001 / 19600)
loss: 1.834948 after (Iteration 11101 / 19600)
loss: 1.873660 after (Iteration 11201 / 19600)
loss: 1.845251 after (Iteration 11301 / 19600)
loss: 1.737216 after (Iteration 11401 / 19600)
loss: 1.640522 after (Iteration 11501 / 19600)
loss: 1.843214 after (Iteration 11601 / 19600)
loss: 1.517141 after (Iteration 11701 / 19600)
(Epoch 12 / 20) train_acc: 0.462000; val_acc: 0.473000
loss: 1.861073 after (Iteration 11801 / 19600)
loss: 1.574910 after (Iteration 11901 / 19600)
loss: 1.646030 after (Iteration 12001 / 19600)
loss: 1.564357 after (Iteration 12101 / 19600)
loss: 1.555329 after (Iteration 12201 / 19600)
loss: 1.739408 after (Iteration 12301 / 19600)
loss: 1.619245 after (Iteration 12401 / 19600)
loss: 1.528329 after (Iteration 12501 / 19600)
loss: 1.796143 after (Iteration 12601 / 19600)
loss: 1.464030 after (Iteration 12701 / 19600)
(Epoch 13 / 20) train_acc: 0.525000; val_acc: 0.484000
loss: 1.793549 after (Iteration 12801 / 19600)
loss: 1.639026 after (Iteration 12901 / 19600)
loss: 1.499299 after (Iteration 13001 / 19600)
loss: 1.893903 after (Iteration 13101 / 19600)
loss: 1.583802 after (Iteration 13201 / 19600)
loss: 1.698824 after (Iteration 13301 / 19600)
loss: 1.755397 after (Iteration 13401 / 19600)
loss: 1.647870 after (Iteration 13501 / 19600)
loss: 1.654572 after (Iteration 13601 / 19600)
loss: 1.942135 after (Iteration 13701 / 19600)
(Epoch 14 / 20) train_acc: 0.481000; val_acc: 0.453000
loss: 1.593654 after (Iteration 13801 / 19600)
loss: 1.378878 after (Iteration 13901 / 19600)
loss: 1.502856 after (Iteration 14001 / 19600)
loss: 1.809255 after (Iteration 14101 / 19600)
loss: 1.620138 after (Iteration 14201 / 19600)
loss: 1.511696 after (Iteration 14301 / 19600)
loss: 1.452141 after (Iteration 14401 / 19600)
loss: 1.514361 after (Iteration 14501 / 19600)
loss: 1.736711 after (Iteration 14601 / 19600)
(Epoch 15 / 20) train_acc: 0.451000; val_acc: 0.435000
loss: 1.491939 after (Iteration 14701 / 19600)
loss: 1.636701 after (Iteration 14801 / 19600)
loss: 1.564358 after (Iteration 14901 / 19600)
loss: 1.954982 after (Iteration 15001 / 19600)
loss: 1.678801 after (Iteration 15101 / 19600)
loss: 1.911223 after (Iteration 15201 / 19600)
loss: 1.626977 after (Iteration 15301 / 19600)
loss: 1.705236 after (Iteration 15401 / 19600)
loss: 1.545868 after (Iteration 15501 / 19600)
loss: 1.696170 after (Iteration 15601 / 19600)
(Epoch 16 / 20) train_acc: 0.478000; val_acc: 0.455000
loss: 1.717093 after (Iteration 15701 / 19600)
loss: 1.698532 after (Iteration 15801 / 19600)
loss: 1.495519 after (Iteration 15901 / 19600)
loss: 1.537704 after (Iteration 16001 / 19600)
loss: 1.574038 after (Iteration 16101 / 19600)
loss: 1.539856 after (Iteration 16201 / 19600)
loss: 1.564734 after (Iteration 16301 / 19600)
loss: 1.475936 after (Iteration 16401 / 19600)
loss: 1.643167 after (Iteration 16501 / 19600)
loss: 1.592014 after (Iteration 16601 / 19600)
(Epoch 17 / 20) train_acc: 0.532000; val_acc: 0.485000
loss: 1.762533 after (Iteration 16701 / 19600)
loss: 1.615629 after (Iteration 16801 / 19600)
loss: 1.733392 after (Iteration 16901 / 19600)
loss: 1.759414 after (Iteration 17001 / 19600)
loss: 1.630668 after (Iteration 17101 / 19600)
loss: 1.661880 after (Iteration 17201 / 19600)
loss: 1.468340 after (Iteration 17301 / 19600)
loss: 1.473620 after (Iteration 17401 / 19600)
loss: 1.588428 after (Iteration 17501 / 19600)
loss: 1.775312 after (Iteration 17601 / 19600)
(Epoch 18 / 20) train_acc: 0.519000; val_acc: 0.483000
loss: 1.713394 after (Iteration 17701 / 19600)
loss: 1.613988 after (Iteration 17801 / 19600)
loss: 1.980984 after (Iteration 17901 / 19600)
loss: 1.582645 after (Iteration 18001 / 19600)
loss: 1.577379 after (Iteration 18101 / 19600)
loss: 1.393591 after (Iteration 18201 / 19600)
loss: 1.578028 after (Iteration 18301 / 19600)
loss: 1.739208 after (Iteration 18401 / 19600)
loss: 1.598028 after (Iteration 18501 / 19600)
loss: 1.353827 after (Iteration 18601 / 19600)
(Epoch 19 / 20) train_acc: 0.538000; val_acc: 0.496000
loss: 1.395769 after (Iteration 18701 / 19600)
loss: 1.623855 after (Iteration 18801 / 19600)
loss: 1.536369 after (Iteration 18901 / 19600)
loss: 1.571687 after (Iteration 19001 / 19600)
loss: 1.532221 after (Iteration 19101 / 19600)
loss: 1.562901 after (Iteration 19201 / 19600)
loss: 1.492828 after (Iteration 19301 / 19600)
loss: 1.542439 after (Iteration 19401 / 19600)
loss: 1.859966 after (Iteration 19501 / 19600)
(Epoch 20 / 20) train_acc: 0.524000; val_acc: 0.463000
Test Accuracy:0.4835