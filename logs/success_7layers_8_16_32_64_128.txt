Loading ../data/train.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "train.h5" (mode r)>)
Loading ../data/test.h5 file
List of arrays in this file: 
 KeysViewWithLock(<HDF5 file "test.h5" (mode r)>)
(50000, 3072)	(50000,)	(10000, 3072)	(10000,)

loss: 9.339210 after (Iteration 1 / 19600)
loss: 8.364297 after (Iteration 101 / 19600)
loss: 8.544644 after (Iteration 201 / 19600)
loss: 8.626348 after (Iteration 301 / 19600)
loss: 9.063451 after (Iteration 401 / 19600)
loss: 9.265395 after (Iteration 501 / 19600)
loss: 9.174889 after (Iteration 601 / 19600)
loss: 9.481525 after (Iteration 701 / 19600)
loss: 9.648736 after (Iteration 801 / 19600)
loss: 10.092733 after (Iteration 901 / 19600)
(Epoch 1 / 20) train_acc: 0.531000; val_acc: 0.532000
loss: 10.223364 after (Iteration 1001 / 19600)
loss: 10.308077 after (Iteration 1101 / 19600)
loss: 10.247976 after (Iteration 1201 / 19600)
loss: 10.402585 after (Iteration 1301 / 19600)
loss: 10.666010 after (Iteration 1401 / 19600)
loss: 11.084630 after (Iteration 1501 / 19600)
loss: 11.062907 after (Iteration 1601 / 19600)
loss: 11.291021 after (Iteration 1701 / 19600)
loss: 11.604446 after (Iteration 1801 / 19600)
loss: 11.564629 after (Iteration 1901 / 19600)
(Epoch 2 / 20) train_acc: 0.584000; val_acc: 0.592000
loss: 11.833017 after (Iteration 2001 / 19600)
loss: 11.961042 after (Iteration 2101 / 19600)
loss: 12.160920 after (Iteration 2201 / 19600)
loss: 12.334380 after (Iteration 2301 / 19600)
loss: 12.550364 after (Iteration 2401 / 19600)
loss: 12.830658 after (Iteration 2501 / 19600)
loss: 12.990380 after (Iteration 2601 / 19600)
loss: 13.019905 after (Iteration 2701 / 19600)
loss: 13.183718 after (Iteration 2801 / 19600)
loss: 13.382012 after (Iteration 2901 / 19600)
(Epoch 3 / 20) train_acc: 0.648000; val_acc: 0.593000
loss: 13.680989 after (Iteration 3001 / 19600)
loss: 13.787329 after (Iteration 3101 / 19600)
loss: 13.812342 after (Iteration 3201 / 19600)
loss: 14.062901 after (Iteration 3301 / 19600)
loss: 14.107153 after (Iteration 3401 / 19600)
loss: 14.377789 after (Iteration 3501 / 19600)
loss: 14.450709 after (Iteration 3601 / 19600)
loss: 14.889749 after (Iteration 3701 / 19600)
loss: 15.060896 after (Iteration 3801 / 19600)
loss: 14.929784 after (Iteration 3901 / 19600)
(Epoch 4 / 20) train_acc: 0.650000; val_acc: 0.643000
loss: 15.172984 after (Iteration 4001 / 19600)
loss: 15.264019 after (Iteration 4101 / 19600)
loss: 15.560975 after (Iteration 4201 / 19600)
loss: 15.648626 after (Iteration 4301 / 19600)
loss: 15.895806 after (Iteration 4401 / 19600)
loss: 16.055343 after (Iteration 4501 / 19600)
loss: 16.332601 after (Iteration 4601 / 19600)
loss: 16.436135 after (Iteration 4701 / 19600)
loss: 16.769205 after (Iteration 4801 / 19600)
(Epoch 5 / 20) train_acc: 0.708000; val_acc: 0.651000
loss: 16.559853 after (Iteration 4901 / 19600)
loss: 16.854732 after (Iteration 5001 / 19600)
loss: 17.147631 after (Iteration 5101 / 19600)
loss: 17.069391 after (Iteration 5201 / 19600)
loss: 17.527387 after (Iteration 5301 / 19600)
loss: 17.371245 after (Iteration 5401 / 19600)
loss: 17.319056 after (Iteration 5501 / 19600)
loss: 17.704311 after (Iteration 5601 / 19600)
loss: 17.942144 after (Iteration 5701 / 19600)
loss: 18.129996 after (Iteration 5801 / 19600)
(Epoch 6 / 20) train_acc: 0.709000; val_acc: 0.657000
loss: 18.173166 after (Iteration 5901 / 19600)
loss: 18.245045 after (Iteration 6001 / 19600)
loss: 18.422663 after (Iteration 6101 / 19600)
loss: 18.614427 after (Iteration 6201 / 19600)
loss: 18.634873 after (Iteration 6301 / 19600)
loss: 18.801795 after (Iteration 6401 / 19600)
loss: 19.348672 after (Iteration 6501 / 19600)
loss: 19.070323 after (Iteration 6601 / 19600)
loss: 19.621229 after (Iteration 6701 / 19600)
loss: 19.529070 after (Iteration 6801 / 19600)
(Epoch 7 / 20) train_acc: 0.744000; val_acc: 0.649000
loss: 19.656999 after (Iteration 6901 / 19600)
loss: 19.570298 after (Iteration 7001 / 19600)
loss: 19.938030 after (Iteration 7101 / 19600)
loss: 20.018589 after (Iteration 7201 / 19600)
loss: 20.015294 after (Iteration 7301 / 19600)
loss: 20.398771 after (Iteration 7401 / 19600)
loss: 20.363682 after (Iteration 7501 / 19600)
loss: 20.556170 after (Iteration 7601 / 19600)
loss: 20.463865 after (Iteration 7701 / 19600)
loss: 20.674922 after (Iteration 7801 / 19600)
(Epoch 8 / 20) train_acc: 0.738000; val_acc: 0.645000
loss: 20.800143 after (Iteration 7901 / 19600)
loss: 21.017248 after (Iteration 8001 / 19600)
loss: 21.163137 after (Iteration 8101 / 19600)
loss: 21.379764 after (Iteration 8201 / 19600)
loss: 21.493524 after (Iteration 8301 / 19600)
loss: 21.598413 after (Iteration 8401 / 19600)
loss: 21.848899 after (Iteration 8501 / 19600)
loss: 21.916105 after (Iteration 8601 / 19600)
loss: 22.037413 after (Iteration 8701 / 19600)
loss: 21.974453 after (Iteration 8801 / 19600)
(Epoch 9 / 20) train_acc: 0.795000; val_acc: 0.658000
loss: 22.196812 after (Iteration 8901 / 19600)
loss: 22.493427 after (Iteration 9001 / 19600)
loss: 22.393513 after (Iteration 9101 / 19600)
loss: 22.652303 after (Iteration 9201 / 19600)
loss: 22.610643 after (Iteration 9301 / 19600)
loss: 22.601320 after (Iteration 9401 / 19600)
loss: 22.666532 after (Iteration 9501 / 19600)
loss: 22.886939 after (Iteration 9601 / 19600)
loss: 22.925842 after (Iteration 9701 / 19600)
(Epoch 10 / 20) train_acc: 0.795000; val_acc: 0.674000
loss: 22.929405 after (Iteration 9801 / 19600)
loss: 23.052708 after (Iteration 9901 / 19600)
loss: 23.305791 after (Iteration 10001 / 19600)
loss: 23.425843 after (Iteration 10101 / 19600)
loss: 23.660161 after (Iteration 10201 / 19600)
loss: 23.671482 after (Iteration 10301 / 19600)
loss: 23.739111 after (Iteration 10401 / 19600)
loss: 23.851666 after (Iteration 10501 / 19600)
loss: 24.065789 after (Iteration 10601 / 19600)
loss: 24.292599 after (Iteration 10701 / 19600)
(Epoch 11 / 20) train_acc: 0.775000; val_acc: 0.668000
loss: 24.286731 after (Iteration 10801 / 19600)
loss: 24.317101 after (Iteration 10901 / 19600)
loss: 24.423728 after (Iteration 11001 / 19600)
loss: 24.611925 after (Iteration 11101 / 19600)
loss: 24.794865 after (Iteration 11201 / 19600)
loss: 24.781116 after (Iteration 11301 / 19600)
loss: 24.837153 after (Iteration 11401 / 19600)
loss: 24.738714 after (Iteration 11501 / 19600)
loss: 24.890999 after (Iteration 11601 / 19600)
loss: 25.020666 after (Iteration 11701 / 19600)
(Epoch 12 / 20) train_acc: 0.838000; val_acc: 0.665000
loss: 25.189275 after (Iteration 11801 / 19600)
loss: 25.152198 after (Iteration 11901 / 19600)
loss: 25.420321 after (Iteration 12001 / 19600)
loss: 25.574060 after (Iteration 12101 / 19600)
loss: 25.543826 after (Iteration 12201 / 19600)
loss: 25.936740 after (Iteration 12301 / 19600)
loss: 25.685269 after (Iteration 12401 / 19600)
loss: 25.690355 after (Iteration 12501 / 19600)
loss: 26.028472 after (Iteration 12601 / 19600)
loss: 26.168565 after (Iteration 12701 / 19600)
(Epoch 13 / 20) train_acc: 0.835000; val_acc: 0.660000
loss: 25.985112 after (Iteration 12801 / 19600)
loss: 26.093629 after (Iteration 12901 / 19600)
loss: 26.692796 after (Iteration 13001 / 19600)
loss: 26.522365 after (Iteration 13101 / 19600)
loss: 26.387018 after (Iteration 13201 / 19600)
loss: 26.469248 after (Iteration 13301 / 19600)
loss: 26.688677 after (Iteration 13401 / 19600)
loss: 26.802064 after (Iteration 13501 / 19600)
loss: 26.850626 after (Iteration 13601 / 19600)
loss: 26.850166 after (Iteration 13701 / 19600)
(Epoch 14 / 20) train_acc: 0.859000; val_acc: 0.653000
loss: 26.981497 after (Iteration 13801 / 19600)
loss: 27.290290 after (Iteration 13901 / 19600)
loss: 27.183668 after (Iteration 14001 / 19600)
loss: 27.287063 after (Iteration 14101 / 19600)
loss: 27.384134 after (Iteration 14201 / 19600)
loss: 27.526888 after (Iteration 14301 / 19600)
loss: 27.334892 after (Iteration 14401 / 19600)
loss: 27.449277 after (Iteration 14501 / 19600)
loss: 27.681621 after (Iteration 14601 / 19600)
(Epoch 15 / 20) train_acc: 0.846000; val_acc: 0.658000
loss: 27.755288 after (Iteration 14701 / 19600)
loss: 27.812035 after (Iteration 14801 / 19600)
loss: 27.778391 after (Iteration 14901 / 19600)
loss: 28.040986 after (Iteration 15001 / 19600)
loss: 28.227964 after (Iteration 15101 / 19600)
loss: 27.837842 after (Iteration 15201 / 19600)
loss: 28.330782 after (Iteration 15301 / 19600)
loss: 28.312653 after (Iteration 15401 / 19600)
loss: 28.384099 after (Iteration 15501 / 19600)
loss: 28.400762 after (Iteration 15601 / 19600)
(Epoch 16 / 20) train_acc: 0.859000; val_acc: 0.673000
loss: 28.457997 after (Iteration 15701 / 19600)
loss: 28.521762 after (Iteration 15801 / 19600)
loss: 28.505960 after (Iteration 15901 / 19600)
loss: 28.683870 after (Iteration 16001 / 19600)
loss: 28.830429 after (Iteration 16101 / 19600)
loss: 28.883285 after (Iteration 16201 / 19600)
loss: 28.869563 after (Iteration 16301 / 19600)
loss: 28.799742 after (Iteration 16401 / 19600)
loss: 29.023929 after (Iteration 16501 / 19600)
loss: 29.154998 after (Iteration 16601 / 19600)
(Epoch 17 / 20) train_acc: 0.882000; val_acc: 0.656000
loss: 29.065122 after (Iteration 16701 / 19600)
loss: 29.195627 after (Iteration 16801 / 19600)
loss: 29.454762 after (Iteration 16901 / 19600)
loss: 29.312033 after (Iteration 17001 / 19600)
loss: 29.333771 after (Iteration 17101 / 19600)
loss: 29.820612 after (Iteration 17201 / 19600)
loss: 29.885650 after (Iteration 17301 / 19600)
loss: 29.539777 after (Iteration 17401 / 19600)
loss: 29.594196 after (Iteration 17501 / 19600)
loss: 29.774442 after (Iteration 17601 / 19600)
(Epoch 18 / 20) train_acc: 0.913000; val_acc: 0.666000
loss: 29.698736 after (Iteration 17701 / 19600)
loss: 30.132977 after (Iteration 17801 / 19600)
loss: 29.958105 after (Iteration 17901 / 19600)
loss: 30.145012 after (Iteration 18001 / 19600)
loss: 30.089463 after (Iteration 18101 / 19600)
loss: 30.105740 after (Iteration 18201 / 19600)
loss: 30.044029 after (Iteration 18301 / 19600)
loss: 30.431238 after (Iteration 18401 / 19600)
loss: 30.150768 after (Iteration 18501 / 19600)
loss: 30.264630 after (Iteration 18601 / 19600)
(Epoch 19 / 20) train_acc: 0.902000; val_acc: 0.667000
loss: 30.236700 after (Iteration 18701 / 19600)
loss: 30.406440 after (Iteration 18801 / 19600)
loss: 30.930870 after (Iteration 18901 / 19600)
loss: 30.511787 after (Iteration 19001 / 19600)
loss: 30.732151 after (Iteration 19101 / 19600)
loss: 30.687136 after (Iteration 19201 / 19600)
loss: 30.690310 after (Iteration 19301 / 19600)
loss: 30.832184 after (Iteration 19401 / 19600)
loss: 30.896729 after (Iteration 19501 / 19600)
(Epoch 20 / 20) train_acc: 0.924000; val_acc: 0.639000
Test Accuracy:0.6712